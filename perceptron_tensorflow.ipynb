{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "perceptron tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacr2006/tensorflow/blob/master/perceptron_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNVMJWROy7Ks",
        "colab_type": "text"
      },
      "source": [
        "##Perceptron\n",
        "\n",
        "El propósito de este notebook es entrenar un Perceptrón (Red Neuronal de una capa) para un problema de clasificación multiclase de digitos escritos a mano. Finalmente se tratará de inferir la clase a la que pertenece una imagen de un digito escritos a mano. Para el entrenamiento usaremos el dataset MNIST conformado por 60.000 imagenes de entrenamiento y 10.000 imagenes de prueba.\n",
        "\n",
        "Es posible usar un Perceptron para este problema porque de antemano sabemos que el conjunto de entranamiento el linealmente separable.\n",
        "Este dataset esta disponible en la libreria \"tensorflow_datasets\" de tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zpbK3ahzsEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tensorflow tensorflow-datasets matplotlib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmpqvCuTe7ZB",
        "colab_type": "text"
      },
      "source": [
        "Importar las librerias necesarias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zY_tbRdcgwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmWD9Bh7lMc7",
        "colab_type": "text"
      },
      "source": [
        "###Datos\n",
        "En este dataset la data de entrada es un conjunto imagenes que estan centradas y estandarizadas en tamaño (28X28x1 pixels, en blanco y negro), no es requerida limpieza de los datos. La data de salida esta conformada por un conjuto finito de datos etiquetados entre el valor 0 y el 9, data categórica.\n",
        "Lectura de los datos de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcHVhWLQ1xM2",
        "colab_type": "code",
        "outputId": "dce77296-40f9-406d-b56f-a0b19679a5b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "train_ds = tfds.load(\"mnist\", split=tfds.Split.TRAIN, batch_size=-1)\n",
        "numpy_ds = tfds.as_numpy(train_ds)\n",
        "numpy_images, numpy_labels = numpy_ds[\"image\"], numpy_ds[\"label\"]"
      ],
      "execution_count": 390,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0901 02:14:33.421324 140523261151104 dataset_builder.py:439] Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kxoiod2_hjK",
        "colab_type": "code",
        "outputId": "4d1c0a8b-3838-4d1a-ea4b-54a9e4d550dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "numpy_images.shape"
      ],
      "execution_count": 391,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 391
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAE803OqmPx2",
        "colab_type": "text"
      },
      "source": [
        "Como la entrada al Perceptron debe ser de una dimension, se requiere una transformacion de la data de entrada de 60000x28x28x1 a 60000x784"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRzVt5hYbByQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numpy_images=numpy_images.reshape(60000,784)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSHsUaUpUqgs",
        "colab_type": "code",
        "outputId": "2510ed7c-307b-4cd3-c99e-f82218d1a3de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "numpy_images.shape"
      ],
      "execution_count": 393,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 393
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgclhEqP9yNt",
        "colab_type": "text"
      },
      "source": [
        "La siguiente figura muestra la imagen de un numero perteneciente al conjunto de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzbUa6Rrtebk",
        "colab_type": "code",
        "outputId": "0dc5967c-b2e6-4c22-c957-9fdcfb4818d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "image_index = 42 \n",
        "img=numpy_images[image_index].reshape(28,28)\n",
        "plt.imshow(img, cmap=\"gray\")"
      ],
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcd4dcbfba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 394
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_KN0Yw6DGLD",
        "colab_type": "code",
        "outputId": "5f1c824b-d600-4e47-fc90-d6bebbfaca88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "numpy_labels.shape"
      ],
      "execution_count": 395,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 395
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxpqZOi4nIe3",
        "colab_type": "text"
      },
      "source": [
        "Lectura de los datos de prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJhRTr97Z7uV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_ds = tfds.load(\"mnist\", split=tfds.Split.TEST, batch_size=-1)\n",
        "numpy_ds_test = tfds.as_numpy(test_ds)\n",
        "numpy_images_test, numpy_labels_test = numpy_ds_test[\"image\"], numpy_ds_test[\"label\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzWroSUra6lp",
        "colab_type": "code",
        "outputId": "516b4ff5-feb1-43a4-e0a2-8376ce4ed28f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "numpy_images_test.shape"
      ],
      "execution_count": 397,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 397
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTvF0A92azy5",
        "colab_type": "code",
        "outputId": "7f4387f5-ab4f-43c9-b6c5-f357c1be19d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "numpy_images_test=numpy_images_test.reshape(10000,784)\n",
        "numpy_images_test.shape"
      ],
      "execution_count": 398,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 398
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pV7pwioKNW_r",
        "outputId": "a4a6bbe3-dab6-4fcb-b0b4-e18ed16e231f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "sess = tf.InteractiveSession()#se crea una sesion interativa, ideal para notebooks"
      ],
      "execution_count": 399,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvTrEfCZzO7G",
        "colab_type": "text"
      },
      "source": [
        "Los algoritmos de \"machine learning\" no funcionan bien con data categorica directamente. Por tanto, se deben codificar estas categorias numéricas en vectores binarios. Para este caso donde existen 10 clases de salida representadas por un valor decimal entre 0 y 9. Se codificaran en un vector binario 1x10 donde solo existe una columna con un valor 1 mientras el resto son 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th2gOhq2ETUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numpy_labels=tf.one_hot(numpy_labels, depth=10)\n",
        "labels=sess.run(numpy_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qp1qcaH41az",
        "colab_type": "code",
        "outputId": "2793c0a0-8268-476e-bea3-7f14f7f57f26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 401
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UsfdPiq2_6V",
        "colab_type": "text"
      },
      "source": [
        "Se realiza la misma codificación para el conjunto de prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gX1U2nuaRZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numpy_labels_test=tf.one_hot(numpy_labels_test, depth=10)\n",
        "labels_test=sess.run(numpy_labels_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSVD5fl9M3Vd",
        "colab_type": "code",
        "outputId": "21a91a9b-973d-4e66-a6aa-08908b9f120b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels_test.shape"
      ],
      "execution_count": 403,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 403
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2IDtYKO5JBc",
        "colab_type": "text"
      },
      "source": [
        "###Entrenamiento\n",
        "Se crean \"placeHolders\" para la variables de entrada (x) y la de salida (y_)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVg2nfu-ETgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x  = tf.placeholder(tf.float32, shape=[None, 784])\n",
        "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxfYy0aeCT6J",
        "colab_type": "text"
      },
      "source": [
        "Se crean las variables del modelo del perceptron y = x * W + b, donde (x) son las imagenes y (y) las etiquetas. W y b son los pesos y bias del modelo respectivamente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQXXiVl2FTiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = tf.Variable(tf.zeros([784, 10],tf.float32))\n",
        "b = tf.Variable(tf.zeros([10],tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVdQK5j4eHdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WE1_Nkw3nze",
        "colab_type": "text"
      },
      "source": [
        "Por definicion el Perceptron utiliza como función de activación \"softmax\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keLF0TVEEf2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = tf.nn.softmax(tf.add(tf.matmul(x,W), b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d68MC6swEkzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D5k00Z16wR6",
        "colab_type": "text"
      },
      "source": [
        "Para este caso, se usa Gradiente Descendente como algoritmo de optimización"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFXZe5UJEk2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate=0.00001#se selecciona un \"learning rate\" pequeño, y se observa la convergencia\n",
        "optimizer=tf.train.GradientDescentOptimizer(learning_rate)\n",
        "train_step = optimizer.minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s95UpkeJ7SnS",
        "colab_type": "text"
      },
      "source": [
        "Se ejecutan un conjunto finito de iteraciones, y se analiza la convergencia mediendo la diferencia entre dos sucesivos valores de costo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtcwWfIdEnyZ",
        "colab_type": "code",
        "outputId": "6084efc5-e729-44d8-b1fe-7ec922d3f90e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cost=0\n",
        "for i in range(1000):\n",
        "    step, new_cross_entropy, new_W, new_b = sess.run([train_step, cross_entropy, W, b], feed_dict={x: numpy_images, y_: labels})\n",
        "    diff=abs(cost-new_cross_entropy)\n",
        "    cost=new_cross_entropy\n",
        "    print(\"Paso: {}, Costo: {}\".format(i, new_cross_entropy) )\n",
        "    if i > 1 and diff < .0001:#usamos un criterio de convergencia de 10-3 para finalizar el entrenamiento\n",
        "      print(\"El entrenamiento converge\")\n",
        "      break\n",
        "    "
      ],
      "execution_count": 410,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Paso: 0, Costo: 2.3025853633880615\n",
            "Paso: 1, Costo: 1.719786286354065\n",
            "Paso: 2, Costo: 1.3874726295471191\n",
            "Paso: 3, Costo: 1.1929572820663452\n",
            "Paso: 4, Costo: 1.0867971181869507\n",
            "Paso: 5, Costo: 0.9944651126861572\n",
            "Paso: 6, Costo: 0.969486653804779\n",
            "Paso: 7, Costo: 0.8473393321037292\n",
            "Paso: 8, Costo: 0.8233635425567627\n",
            "Paso: 9, Costo: 0.7672825455665588\n",
            "Paso: 10, Costo: 0.7526967525482178\n",
            "Paso: 11, Costo: 0.7033041715621948\n",
            "Paso: 12, Costo: 0.6863644123077393\n",
            "Paso: 13, Costo: 0.65372234582901\n",
            "Paso: 14, Costo: 0.6370963454246521\n",
            "Paso: 15, Costo: 0.6150473952293396\n",
            "Paso: 16, Costo: 0.6004779934883118\n",
            "Paso: 17, Costo: 0.5851417183876038\n",
            "Paso: 18, Costo: 0.5731908082962036\n",
            "Paso: 19, Costo: 0.5619328618049622\n",
            "Paso: 20, Costo: 0.5523132681846619\n",
            "Paso: 21, Costo: 0.5435487627983093\n",
            "Paso: 22, Costo: 0.5357035994529724\n",
            "Paso: 23, Costo: 0.5285320281982422\n",
            "Paso: 24, Costo: 0.5219516158103943\n",
            "Paso: 25, Costo: 0.515857458114624\n",
            "Paso: 26, Costo: 0.5101805925369263\n",
            "Paso: 27, Costo: 0.5048637986183167\n",
            "Paso: 28, Costo: 0.4998635947704315\n",
            "Paso: 29, Costo: 0.4951455295085907\n",
            "Paso: 30, Costo: 0.49068164825439453\n",
            "Paso: 31, Costo: 0.4864487051963806\n",
            "Paso: 32, Costo: 0.48242709040641785\n",
            "Paso: 33, Costo: 0.47859957814216614\n",
            "Paso: 34, Costo: 0.4749511480331421\n",
            "Paso: 35, Costo: 0.4714682996273041\n",
            "Paso: 36, Costo: 0.4681391417980194\n",
            "Paso: 37, Costo: 0.4649525284767151\n",
            "Paso: 38, Costo: 0.46189892292022705\n",
            "Paso: 39, Costo: 0.4589693248271942\n",
            "Paso: 40, Costo: 0.4561556279659271\n",
            "Paso: 41, Costo: 0.45345044136047363\n",
            "Paso: 42, Costo: 0.4508470594882965\n",
            "Paso: 43, Costo: 0.4483392834663391\n",
            "Paso: 44, Costo: 0.44592148065567017\n",
            "Paso: 45, Costo: 0.44358834624290466\n",
            "Paso: 46, Costo: 0.44133514165878296\n",
            "Paso: 47, Costo: 0.4391574561595917\n",
            "Paso: 48, Costo: 0.4370511770248413\n",
            "Paso: 49, Costo: 0.43501242995262146\n",
            "Paso: 50, Costo: 0.43303775787353516\n",
            "Paso: 51, Costo: 0.43112388253211975\n",
            "Paso: 52, Costo: 0.4292677640914917\n",
            "Paso: 53, Costo: 0.4274665415287018\n",
            "Paso: 54, Costo: 0.42571762204170227\n",
            "Paso: 55, Costo: 0.42401841282844543\n",
            "Paso: 56, Costo: 0.422366738319397\n",
            "Paso: 57, Costo: 0.4207603633403778\n",
            "Paso: 58, Costo: 0.4191972613334656\n",
            "Paso: 59, Costo: 0.41767555475234985\n",
            "Paso: 60, Costo: 0.4161933958530426\n",
            "Paso: 61, Costo: 0.4147491455078125\n",
            "Paso: 62, Costo: 0.4133411645889282\n",
            "Paso: 63, Costo: 0.41196802258491516\n",
            "Paso: 64, Costo: 0.4106282591819763\n",
            "Paso: 65, Costo: 0.40932056307792664\n",
            "Paso: 66, Costo: 0.40804368257522583\n",
            "Paso: 67, Costo: 0.4067964255809784\n",
            "Paso: 68, Costo: 0.40557757019996643\n",
            "Paso: 69, Costo: 0.4043861925601959\n",
            "Paso: 70, Costo: 0.4032211899757385\n",
            "Paso: 71, Costo: 0.4020816385746002\n",
            "Paso: 72, Costo: 0.4009665548801422\n",
            "Paso: 73, Costo: 0.3998751640319824\n",
            "Paso: 74, Costo: 0.3988065719604492\n",
            "Paso: 75, Costo: 0.3977600336074829\n",
            "Paso: 76, Costo: 0.3967347741127014\n",
            "Paso: 77, Costo: 0.39573007822036743\n",
            "Paso: 78, Costo: 0.3947452902793884\n",
            "Paso: 79, Costo: 0.3937796950340271\n",
            "Paso: 80, Costo: 0.3928327262401581\n",
            "Paso: 81, Costo: 0.3919037878513336\n",
            "Paso: 82, Costo: 0.39099228382110596\n",
            "Paso: 83, Costo: 0.3900977075099945\n",
            "Paso: 84, Costo: 0.3892194926738739\n",
            "Paso: 85, Costo: 0.3883572220802307\n",
            "Paso: 86, Costo: 0.38751035928726196\n",
            "Paso: 87, Costo: 0.38667845726013184\n",
            "Paso: 88, Costo: 0.38586103916168213\n",
            "Paso: 89, Costo: 0.3850577473640442\n",
            "Paso: 90, Costo: 0.3842681646347046\n",
            "Paso: 91, Costo: 0.3834918737411499\n",
            "Paso: 92, Costo: 0.3827285170555115\n",
            "Paso: 93, Costo: 0.38197776675224304\n",
            "Paso: 94, Costo: 0.38123923540115356\n",
            "Paso: 95, Costo: 0.3805125951766968\n",
            "Paso: 96, Costo: 0.3797975778579712\n",
            "Paso: 97, Costo: 0.37909382581710815\n",
            "Paso: 98, Costo: 0.3784010112285614\n",
            "Paso: 99, Costo: 0.3777189552783966\n",
            "Paso: 100, Costo: 0.37704727053642273\n",
            "Paso: 101, Costo: 0.37638580799102783\n",
            "Paso: 102, Costo: 0.3757341802120209\n",
            "Paso: 103, Costo: 0.3750922381877899\n",
            "Paso: 104, Costo: 0.37445974349975586\n",
            "Paso: 105, Costo: 0.3738363981246948\n",
            "Paso: 106, Costo: 0.3732220232486725\n",
            "Paso: 107, Costo: 0.37261641025543213\n",
            "Paso: 108, Costo: 0.37201935052871704\n",
            "Paso: 109, Costo: 0.3714306056499481\n",
            "Paso: 110, Costo: 0.3708500266075134\n",
            "Paso: 111, Costo: 0.37027740478515625\n",
            "Paso: 112, Costo: 0.36971256136894226\n",
            "Paso: 113, Costo: 0.36915531754493713\n",
            "Paso: 114, Costo: 0.36860546469688416\n",
            "Paso: 115, Costo: 0.36806294322013855\n",
            "Paso: 116, Costo: 0.36752748489379883\n",
            "Paso: 117, Costo: 0.3669990301132202\n",
            "Paso: 118, Costo: 0.36647728085517883\n",
            "Paso: 119, Costo: 0.36596226692199707\n",
            "Paso: 120, Costo: 0.3654537498950958\n",
            "Paso: 121, Costo: 0.36495158076286316\n",
            "Paso: 122, Costo: 0.3644556999206543\n",
            "Paso: 123, Costo: 0.3639658987522125\n",
            "Paso: 124, Costo: 0.3634820878505707\n",
            "Paso: 125, Costo: 0.3630041480064392\n",
            "Paso: 126, Costo: 0.3625319302082062\n",
            "Paso: 127, Costo: 0.3620653748512268\n",
            "Paso: 128, Costo: 0.36160433292388916\n",
            "Paso: 129, Costo: 0.3611486852169037\n",
            "Paso: 130, Costo: 0.3606983423233032\n",
            "Paso: 131, Costo: 0.36025315523147583\n",
            "Paso: 132, Costo: 0.3598131537437439\n",
            "Paso: 133, Costo: 0.3593780994415283\n",
            "Paso: 134, Costo: 0.3589479625225067\n",
            "Paso: 135, Costo: 0.3585226535797119\n",
            "Paso: 136, Costo: 0.35810208320617676\n",
            "Paso: 137, Costo: 0.3576860725879669\n",
            "Paso: 138, Costo: 0.3572746813297272\n",
            "Paso: 139, Costo: 0.3568677306175232\n",
            "Paso: 140, Costo: 0.3564651906490326\n",
            "Paso: 141, Costo: 0.35606691241264343\n",
            "Paso: 142, Costo: 0.3556729257106781\n",
            "Paso: 143, Costo: 0.35528308153152466\n",
            "Paso: 144, Costo: 0.35489726066589355\n",
            "Paso: 145, Costo: 0.35451552271842957\n",
            "Paso: 146, Costo: 0.354137659072876\n",
            "Paso: 147, Costo: 0.35376372933387756\n",
            "Paso: 148, Costo: 0.3533935844898224\n",
            "Paso: 149, Costo: 0.3530271351337433\n",
            "Paso: 150, Costo: 0.35266444087028503\n",
            "Paso: 151, Costo: 0.3523053526878357\n",
            "Paso: 152, Costo: 0.3519497811794281\n",
            "Paso: 153, Costo: 0.35159772634506226\n",
            "Paso: 154, Costo: 0.351249098777771\n",
            "Paso: 155, Costo: 0.35090383887290955\n",
            "Paso: 156, Costo: 0.3505619168281555\n",
            "Paso: 157, Costo: 0.3502233028411865\n",
            "Paso: 158, Costo: 0.349887877702713\n",
            "Paso: 159, Costo: 0.3495556116104126\n",
            "Paso: 160, Costo: 0.3492265045642853\n",
            "Paso: 161, Costo: 0.3489004373550415\n",
            "Paso: 162, Costo: 0.3485774099826813\n",
            "Paso: 163, Costo: 0.3482573628425598\n",
            "Paso: 164, Costo: 0.34794023633003235\n",
            "Paso: 165, Costo: 0.3476259708404541\n",
            "Paso: 166, Costo: 0.34731459617614746\n",
            "Paso: 167, Costo: 0.3470059931278229\n",
            "Paso: 168, Costo: 0.34670013189315796\n",
            "Paso: 169, Costo: 0.3463970422744751\n",
            "Paso: 170, Costo: 0.34609654545783997\n",
            "Paso: 171, Costo: 0.3457987308502197\n",
            "Paso: 172, Costo: 0.3455035090446472\n",
            "Paso: 173, Costo: 0.34521085023880005\n",
            "Paso: 174, Costo: 0.34492069482803345\n",
            "Paso: 175, Costo: 0.3446330726146698\n",
            "Paso: 176, Costo: 0.34434786438941956\n",
            "Paso: 177, Costo: 0.3440650403499603\n",
            "Paso: 178, Costo: 0.3437846302986145\n",
            "Paso: 179, Costo: 0.3435065746307373\n",
            "Paso: 180, Costo: 0.34323081374168396\n",
            "Paso: 181, Costo: 0.3429573178291321\n",
            "Paso: 182, Costo: 0.34268614649772644\n",
            "Paso: 183, Costo: 0.3424171209335327\n",
            "Paso: 184, Costo: 0.3421502709388733\n",
            "Paso: 185, Costo: 0.34188562631607056\n",
            "Paso: 186, Costo: 0.34162306785583496\n",
            "Paso: 187, Costo: 0.3413626253604889\n",
            "Paso: 188, Costo: 0.34110429883003235\n",
            "Paso: 189, Costo: 0.3408479690551758\n",
            "Paso: 190, Costo: 0.34059369564056396\n",
            "Paso: 191, Costo: 0.34034135937690735\n",
            "Paso: 192, Costo: 0.3400910496711731\n",
            "Paso: 193, Costo: 0.33984264731407166\n",
            "Paso: 194, Costo: 0.33959612250328064\n",
            "Paso: 195, Costo: 0.3393515348434448\n",
            "Paso: 196, Costo: 0.33910879492759705\n",
            "Paso: 197, Costo: 0.3388679027557373\n",
            "Paso: 198, Costo: 0.3386288285255432\n",
            "Paso: 199, Costo: 0.3383915424346924\n",
            "Paso: 200, Costo: 0.33815598487854004\n",
            "Paso: 201, Costo: 0.33792227506637573\n",
            "Paso: 202, Costo: 0.33769020438194275\n",
            "Paso: 203, Costo: 0.33745989203453064\n",
            "Paso: 204, Costo: 0.33723124861717224\n",
            "Paso: 205, Costo: 0.33700427412986755\n",
            "Paso: 206, Costo: 0.3367789387702942\n",
            "Paso: 207, Costo: 0.33655521273612976\n",
            "Paso: 208, Costo: 0.33633309602737427\n",
            "Paso: 209, Costo: 0.3361125886440277\n",
            "Paso: 210, Costo: 0.3358936309814453\n",
            "Paso: 211, Costo: 0.3356761932373047\n",
            "Paso: 212, Costo: 0.335460364818573\n",
            "Paso: 213, Costo: 0.3352459669113159\n",
            "Paso: 214, Costo: 0.3350330591201782\n",
            "Paso: 215, Costo: 0.3348216712474823\n",
            "Paso: 216, Costo: 0.334611713886261\n",
            "Paso: 217, Costo: 0.33440321683883667\n",
            "Paso: 218, Costo: 0.33419615030288696\n",
            "Paso: 219, Costo: 0.3339904844760895\n",
            "Paso: 220, Costo: 0.3337862193584442\n",
            "Paso: 221, Costo: 0.3335833251476288\n",
            "Paso: 222, Costo: 0.3333817720413208\n",
            "Paso: 223, Costo: 0.33318158984184265\n",
            "Paso: 224, Costo: 0.33298274874687195\n",
            "Paso: 225, Costo: 0.3327851891517639\n",
            "Paso: 226, Costo: 0.33258897066116333\n",
            "Paso: 227, Costo: 0.332394003868103\n",
            "Paso: 228, Costo: 0.3322003185749054\n",
            "Paso: 229, Costo: 0.33200788497924805\n",
            "Paso: 230, Costo: 0.331816703081131\n",
            "Paso: 231, Costo: 0.3316267430782318\n",
            "Paso: 232, Costo: 0.3314380347728729\n",
            "Paso: 233, Costo: 0.33125051856040955\n",
            "Paso: 234, Costo: 0.3310641944408417\n",
            "Paso: 235, Costo: 0.3308790326118469\n",
            "Paso: 236, Costo: 0.3306950628757477\n",
            "Paso: 237, Costo: 0.3305121660232544\n",
            "Paso: 238, Costo: 0.330330491065979\n",
            "Paso: 239, Costo: 0.33014994859695435\n",
            "Paso: 240, Costo: 0.32997050881385803\n",
            "Paso: 241, Costo: 0.32979220151901245\n",
            "Paso: 242, Costo: 0.32961490750312805\n",
            "Paso: 243, Costo: 0.3294387757778168\n",
            "Paso: 244, Costo: 0.3292636573314667\n",
            "Paso: 245, Costo: 0.3290896713733673\n",
            "Paso: 246, Costo: 0.3289166986942291\n",
            "Paso: 247, Costo: 0.3287447690963745\n",
            "Paso: 248, Costo: 0.3285738527774811\n",
            "Paso: 249, Costo: 0.3284039795398712\n",
            "Paso: 250, Costo: 0.32823508977890015\n",
            "Paso: 251, Costo: 0.32806724309921265\n",
            "Paso: 252, Costo: 0.32790032029151917\n",
            "Paso: 253, Costo: 0.32773444056510925\n",
            "Paso: 254, Costo: 0.32756945490837097\n",
            "Paso: 255, Costo: 0.32740554213523865\n",
            "Paso: 256, Costo: 0.32724252343177795\n",
            "Paso: 257, Costo: 0.3270803987979889\n",
            "Paso: 258, Costo: 0.32691922783851624\n",
            "Paso: 259, Costo: 0.3267590403556824\n",
            "Paso: 260, Costo: 0.32659968733787537\n",
            "Paso: 261, Costo: 0.32644131779670715\n",
            "Paso: 262, Costo: 0.3262837827205658\n",
            "Paso: 263, Costo: 0.32612714171409607\n",
            "Paso: 264, Costo: 0.32597142457962036\n",
            "Paso: 265, Costo: 0.3258165419101715\n",
            "Paso: 266, Costo: 0.3256625235080719\n",
            "Paso: 267, Costo: 0.32550936937332153\n",
            "Paso: 268, Costo: 0.32535701990127563\n",
            "Paso: 269, Costo: 0.32520559430122375\n",
            "Paso: 270, Costo: 0.32505494356155396\n",
            "Paso: 271, Costo: 0.3249051570892334\n",
            "Paso: 272, Costo: 0.32475611567497253\n",
            "Paso: 273, Costo: 0.3246079385280609\n",
            "Paso: 274, Costo: 0.32446053624153137\n",
            "Paso: 275, Costo: 0.3243139684200287\n",
            "Paso: 276, Costo: 0.3241681754589081\n",
            "Paso: 277, Costo: 0.3240230977535248\n",
            "Paso: 278, Costo: 0.32387885451316833\n",
            "Paso: 279, Costo: 0.32373538613319397\n",
            "Paso: 280, Costo: 0.3235926330089569\n",
            "Paso: 281, Costo: 0.32345065474510193\n",
            "Paso: 282, Costo: 0.32330945134162903\n",
            "Paso: 283, Costo: 0.32316893339157104\n",
            "Paso: 284, Costo: 0.32302916049957275\n",
            "Paso: 285, Costo: 0.32289016246795654\n",
            "Paso: 286, Costo: 0.32275182008743286\n",
            "Paso: 287, Costo: 0.3226141929626465\n",
            "Paso: 288, Costo: 0.3224773406982422\n",
            "Paso: 289, Costo: 0.32234111428260803\n",
            "Paso: 290, Costo: 0.3222056031227112\n",
            "Paso: 291, Costo: 0.32207080721855164\n",
            "Paso: 292, Costo: 0.3219366669654846\n",
            "Paso: 293, Costo: 0.32180318236351013\n",
            "Paso: 294, Costo: 0.32167038321495056\n",
            "Paso: 295, Costo: 0.3215382695198059\n",
            "Paso: 296, Costo: 0.32140684127807617\n",
            "Paso: 297, Costo: 0.3212760090827942\n",
            "Paso: 298, Costo: 0.3211458623409271\n",
            "Paso: 299, Costo: 0.3210163414478302\n",
            "Paso: 300, Costo: 0.3208874762058258\n",
            "Paso: 301, Costo: 0.32075923681259155\n",
            "Paso: 302, Costo: 0.32063165307044983\n",
            "Paso: 303, Costo: 0.32050463557243347\n",
            "Paso: 304, Costo: 0.32037824392318726\n",
            "Paso: 305, Costo: 0.3202524781227112\n",
            "Paso: 306, Costo: 0.32012730836868286\n",
            "Paso: 307, Costo: 0.3200027644634247\n",
            "Paso: 308, Costo: 0.31987881660461426\n",
            "Paso: 309, Costo: 0.3197554051876068\n",
            "Paso: 310, Costo: 0.3196326494216919\n",
            "Paso: 311, Costo: 0.31951045989990234\n",
            "Paso: 312, Costo: 0.31938880681991577\n",
            "Paso: 313, Costo: 0.31926780939102173\n",
            "Paso: 314, Costo: 0.3191473186016083\n",
            "Paso: 315, Costo: 0.3190273940563202\n",
            "Paso: 316, Costo: 0.3189080059528351\n",
            "Paso: 317, Costo: 0.3187892436981201\n",
            "Paso: 318, Costo: 0.31867095828056335\n",
            "Paso: 319, Costo: 0.31855326890945435\n",
            "Paso: 320, Costo: 0.3184361457824707\n",
            "Paso: 321, Costo: 0.31831949949264526\n",
            "Paso: 322, Costo: 0.3182033896446228\n",
            "Paso: 323, Costo: 0.3180878460407257\n",
            "Paso: 324, Costo: 0.3179728090763092\n",
            "Paso: 325, Costo: 0.3178583085536957\n",
            "Paso: 326, Costo: 0.31774431467056274\n",
            "Paso: 327, Costo: 0.3176308274269104\n",
            "Paso: 328, Costo: 0.31751784682273865\n",
            "Paso: 329, Costo: 0.3174054026603699\n",
            "Paso: 330, Costo: 0.3172934353351593\n",
            "Paso: 331, Costo: 0.3171819746494293\n",
            "Paso: 332, Costo: 0.31707099080085754\n",
            "Paso: 333, Costo: 0.31696054339408875\n",
            "Paso: 334, Costo: 0.3168505132198334\n",
            "Paso: 335, Costo: 0.316741019487381\n",
            "Paso: 336, Costo: 0.3166319727897644\n",
            "Paso: 337, Costo: 0.3165234327316284\n",
            "Paso: 338, Costo: 0.31641536951065063\n",
            "Paso: 339, Costo: 0.31630775332450867\n",
            "Paso: 340, Costo: 0.3162005841732025\n",
            "Paso: 341, Costo: 0.31609389185905457\n",
            "Paso: 342, Costo: 0.3159877061843872\n",
            "Paso: 343, Costo: 0.3158819079399109\n",
            "Paso: 344, Costo: 0.3157765865325928\n",
            "Paso: 345, Costo: 0.31567174196243286\n",
            "Paso: 346, Costo: 0.3155673146247864\n",
            "Paso: 347, Costo: 0.3154633343219757\n",
            "Paso: 348, Costo: 0.31535977125167847\n",
            "Paso: 349, Costo: 0.31525668501853943\n",
            "Paso: 350, Costo: 0.3151540160179138\n",
            "Paso: 351, Costo: 0.31505176424980164\n",
            "Paso: 352, Costo: 0.3149499297142029\n",
            "Paso: 353, Costo: 0.31484857201576233\n",
            "Paso: 354, Costo: 0.3147476017475128\n",
            "Paso: 355, Costo: 0.31464701890945435\n",
            "Paso: 356, Costo: 0.3145468831062317\n",
            "Paso: 357, Costo: 0.3144471347332001\n",
            "El entrenamiento converge\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CAhCnuPToty",
        "colab_type": "text"
      },
      "source": [
        "Se determina la precision del modelo con los datos del conjunto de prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7fpKmxLY866",
        "colab_type": "code",
        "outputId": "025628e2-23b8-4816-f7fe-fd934f4ff84d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))*100\n",
        "resul=tf.print(\"La precision del modelo es:\", accuracy)\n",
        "resul=sess.run(resul, feed_dict={x: numpy_images_test, y_: labels_test} )"
      ],
      "execution_count": 411,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La precision del modelo es: 91.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV56p0HJW6dg",
        "colab_type": "text"
      },
      "source": [
        "###Inferencia\n",
        "Con los parametros del modelo ya obtenidos, se selecciona una imagen aleatoria del conjunto de prueba y se hace pasar a traves del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgbMOOLbTwnY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "4c299ca6-2613-4e7b-ca18-1a1685c66985"
      },
      "source": [
        "image_index = 5672\n",
        "img=numpy_images_test[image_index].reshape(28,28)\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "\n",
        "prediction=tf.nn.softmax( tf.add( tf.matmul( tf.cast(tf.expand_dims( numpy_images_test[image_index],0), tf.float32), tf.cast(new_W, tf.float32) ), new_b ) )\n",
        "encode=tf.argmax(prediction, axis=1)#la predicion obtenida es un vector binario, se debe codificar a un valor numérico\n",
        "res=tf.print(\"El valor inferido es:\", encode)\n",
        "sess.run(res)"
      ],
      "execution_count": 412,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El valor inferido es: [6]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHwiK8ANBEX4gKMIPBEX4gaAIPxDU/wD/4FMqFaFerwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OAmO9qSEn2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.close() "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}